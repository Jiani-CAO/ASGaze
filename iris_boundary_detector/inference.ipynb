{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:\\\\ASGaze\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "\n",
    "import import_ipynb\n",
    "import iris_boundary_detector.utils.refinement as refinement\n",
    "from iris_boundary_detector.data_sources.ASGaze_data import ASGaze_data\n",
    "from iris_boundary_detector.graph.vgg_unet import get_model\n",
    "from iris_boundary_detector.utils.load_model import data_gpu,load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(val_loader, model, left_or_right, out_dir, video):\n",
    "    model.eval()\n",
    "\n",
    "    rect_trans_list = []\n",
    "    full_img_list = []\n",
    "    crop_img_list = []\n",
    "    entropy_partial_list = []\n",
    "    \n",
    "    for i, (data_id, img, rect_trans,full_img) in enumerate(val_loader):\n",
    "        rect_trans_list.append(rect_trans)\n",
    "        full_img_list.append(full_img)\n",
    "        \n",
    "        out = model(data_gpu(img, device))\n",
    "        \n",
    "        prob = f.softmax(out, dim=1).cpu().numpy()\n",
    "        prob_mask = torch.argmax(f.softmax(out, dim=1), dim=1).cpu().numpy()[0] # Most likely class  \n",
    "        prob_mask_2 = torch.argmin(f.softmax(out, dim=1), dim=1).cpu().numpy()[0] # Least likely class\n",
    "        crop_img = img.cpu().numpy()[0]\n",
    "        crop_img_list.append(crop_img)\n",
    "        \n",
    "        # Complete entropy \n",
    "        entropy = np.sum(-prob*np.log(prob),axis=1)[0] \n",
    "        entropy = (entropy-entropy.min())/(entropy.max()-entropy.min())*255\n",
    "        cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,data_id[0]+\"_entropy.png\"),np.abs(entropy-255))\n",
    "\n",
    "        # Partial entropy\n",
    "        entropy_partial = np.sum(-prob[:,1:3,:,:]*np.log(prob[:,1:3,:,:]),axis=1)[0] # Relative entropy to quantify an uncertainty cross [iris,sclera]    \n",
    "        entropy_partial[np.isnan(entropy_partial)] = 0\n",
    "        entropy_filter = np.zeros(shape=entropy_partial.shape)\n",
    "        row,col = np.where(prob_mask_2==0) # Least likely to be {background} (most likely to be {iris,sclera})\n",
    "        entropy_filter[row,col] = 1\n",
    "\n",
    "        entropy_partial = entropy_partial*entropy_filter\n",
    "        entropy_partial = (entropy_partial-entropy_partial.min())/(entropy_partial.max()-entropy_partial.min())*255\n",
    "\n",
    "        base_img_mask = cv2.threshold(entropy_partial.astype(np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1] # Binarization image\n",
    "        rows,cols = np.where(base_img_mask==0) \n",
    "        entropy_partial[rows,cols] = 0\n",
    "        entropy_partial_list.append(entropy_partial)\n",
    "        cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,data_id[0]+\"_entropy_p.png\"),np.abs(entropy_partial-255))\n",
    "\n",
    "        # Write video (optional)\n",
    "        if video:\n",
    "            entropy_img = (np.abs(entropy)).astype(np.uint8)\n",
    "            entropy_partial_img = (np.abs(entropy_partial-255)).astype(np.uint8)\n",
    "            if(left_or_right == \"left\"):\n",
    "                video_entropy_left.write(cv2.cvtColor(entropy_img, cv2.COLOR_GRAY2RGB))\n",
    "                video_entropy_partial_left.write(cv2.cvtColor(entropy_partial_img, cv2.COLOR_GRAY2RGB))\n",
    "            else:\n",
    "                video_entropy_right.write(cv2.cvtColor(entropy_img, cv2.COLOR_GRAY2RGB))\n",
    "                video_entropy_partial_right.write(cv2.cvtColor(entropy_partial_img, cv2.COLOR_GRAY2RGB))\n",
    "    \n",
    "    #--------------Fit ellipse----------#    \n",
    "    global temp_img  \n",
    "    flag_l,pt1_l,pt2_l,flag_r,pt1_r,pt2_r = refinement.is_feature_matching_all(entropy_partial_list[0].astype(np.uint8),entropy_partial_list[1].astype(np.uint8))\n",
    "    if(flag_l == True and flag_r == True):# The number of matches in the left and right parts of both images is greater than threshhold\n",
    "        img1_new,points1,img2_new,points2 = refinement.feature_remove(entropy_partial_list[0].astype(np.uint8),entropy_partial_list[1].astype(np.uint8),pt1_l,pt2_l,pt1_r,pt2_r)\n",
    "        # cv2 ellipse fitting (least square)\n",
    "        e11= cv2.fitEllipse(np.array(points1).T) # Point1\n",
    "        e21 = refinement.rect_transform(e11, rect_trans_list[0][0].numpy())\n",
    "        cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(0)+\"_entropy_p_fr.png\"),np.abs(255-img1_new))\n",
    "\n",
    "        e12= cv2.fitEllipse(np.array(points2).T) # Point2\n",
    "        e22 = refinement.rect_transform(e12, rect_trans_list[1][0].numpy())\n",
    "        cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(1)+\"_entropy_p_fr.png\"),np.abs(255-img2_new))\n",
    "\n",
    "        temp_img = img2_new\n",
    "        \n",
    "        refine_img1 = (np.abs(255-img1_new)).astype(np.uint8)\n",
    "        refine_img2 = (np.abs(255-img2_new)).astype(np.uint8)\n",
    "            \n",
    "    else: \n",
    "        # Not enough pixels to match\n",
    "        print(\"initial else\")\n",
    "        entropy_fd1,entropy_fd_points1 = refinement.feature_detect(entropy_partial_list[0].astype(np.uint8))\n",
    "        e11= cv2.fitEllipse(np.array(entropy_fd_points1).T) # Point1\n",
    "        e21 = refinement.rect_transform(e11, rect_trans_list[0][0].numpy())\n",
    "        cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(0)+\"_entropy_p_fd.png\"),np.abs(255-entropy_fd1))\n",
    "        \n",
    "        entropy_fd2,entropy_fd_points2 = refinement.feature_detect(entropy_partial_list[1].astype(np.uint8))\n",
    "        e12= cv2.fitEllipse(np.array(entropy_fd_points2).T) # Point2\n",
    "        e22 = refinement.rect_transform(e12, rect_trans_list[1][0].numpy())\n",
    "        cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(1)+\"_entropy_p_fd.png\"),np.abs(255-entropy_fd2))\n",
    "        \n",
    "        temp_img = entropy_fd2\n",
    "        \n",
    "        refine_img1 = (np.abs(255-entropy_fd1)).astype(np.uint8)\n",
    "        refine_img2 = (np.abs(255-entropy_fd2)).astype(np.uint8)\n",
    "\n",
    "    full_img = cv2.ellipse(cv2.cvtColor(full_img_list[0][0].numpy(),cv2.COLOR_RGB2BGR),e21,(0,255,255),1)\n",
    "#     cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(0)+\".png\"),full_img)\n",
    "    crop_img = (np.transpose(crop_img_list[0]+1,(1,2,0))*255/2).astype(np.uint8)\n",
    "    crop_img = cv2.cvtColor(crop_img,cv2.COLOR_RGB2BGR)\n",
    "    crop_img = cv2.ellipse(crop_img,e11,(0,255,255),1)\n",
    "    cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(0)+\"_crop.png\"),crop_img)\n",
    "    \n",
    "    full_img = cv2.ellipse(cv2.cvtColor(full_img_list[1][0].numpy(),cv2.COLOR_RGB2BGR),e22,(0,255,255),1)\n",
    "#     cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(1)+\".png\"),full_img)\n",
    "    crop_img = (np.transpose(crop_img_list[1]+1,(1,2,0))*255/2).astype(np.uint8)\n",
    "    crop_img = cv2.cvtColor(crop_img,cv2.COLOR_RGB2BGR)\n",
    "    crop_img = cv2.ellipse(crop_img,e12,(0,255,255),1)\n",
    "    cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(1)+\"_crop.png\"),crop_img)\n",
    "    refinement.write_ellipse_params(e21, os.path.join(out_dir,\"ellipse_params_\"+left_or_right,\"{:05}\".format(0)+\".ini\"))\n",
    "    refinement.write_ellipse_params(e22, os.path.join(out_dir,\"ellipse_params_\"+left_or_right,\"{:05}\".format(1)+\".ini\"))\n",
    "    \n",
    "    # Wirte video (optional)\n",
    "    if video:\n",
    "        if(left_or_right == \"left\"):\n",
    "            video_refine_left.write(cv2.cvtColor(refine_img1, cv2.COLOR_GRAY2RGB))\n",
    "            video_refine_left.write(cv2.cvtColor(refine_img2, cv2.COLOR_GRAY2RGB))\n",
    "        else:\n",
    "            video_refine_right.write(cv2.cvtColor(refine_img1, cv2.COLOR_GRAY2RGB))\n",
    "            video_refine_right.write(cv2.cvtColor(refine_img2, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "    for idx in range(2,len(entropy_partial_list)):\n",
    "        flag_l,pt1_l,pt2_l,flag_r,pt1_r,pt2_r = refinement.is_feature_matching_all(temp_img.astype(np.uint8),entropy_partial_list[idx].astype(np.uint8))\n",
    "        if(flag_l == True and flag_r == True):\n",
    "            _,_,img_new,points = refinement.feature_remove(temp_img.astype(np.uint8),entropy_partial_list[idx].astype(np.uint8),pt1_l,pt2_l,pt1_r,pt2_r)\n",
    "            final_points = points\n",
    "            cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(idx)+\"_entropy_p_fr.png\"),np.abs(255-img_new))\n",
    "\n",
    "            temp_img = img_new\n",
    "            \n",
    "        else:\n",
    "            print(\"else\")\n",
    "            entropy_fd,entropy_fd_points = refinement.feature_detect(entropy_partial_list[idx].astype(np.uint8))\n",
    "            final_points = entropy_fd_points\n",
    "            cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(idx)+\"_entropy_p_fd.png\"),np.abs(255-entropy_fd))\n",
    "        \n",
    "            temp_img = entropy_fd  \n",
    "            \n",
    "        e1= cv2.fitEllipse(np.array(final_points).T)\n",
    "        e2 = refinement.rect_transform(e1, rect_trans_list[idx][0].numpy())\n",
    "        full_img = cv2.ellipse(cv2.cvtColor(full_img_list[idx][0].numpy(),cv2.COLOR_RGB2BGR),e2,(0,255,255),1)\n",
    "#         cv2.imwrite(os.path.join(visual,\"visual_\"+left_or_right,\"{:05}\".format(idx)+\".png\"),full_img)\n",
    "        crop_img = (np.transpose(crop_img_list[idx]+1,(1,2,0))*255/2).astype(np.uint8)\n",
    "        crop_img = cv2.cvtColor(crop_img,cv2.COLOR_RGB2BGR)\n",
    "        crop_img = cv2.ellipse(crop_img,e1,(0,255,255),1)\n",
    "        cv2.imwrite(os.path.join(out_dir,\"visual_\"+left_or_right,\"{:05}\".format(idx)+\"_crop.png\"),crop_img)\n",
    "        refinement.write_ellipse_params(e2, os.path.join(out_dir,\"ellipse_params_\"+left_or_right,\"{:05}\".format(idx)+\".ini\"))\n",
    "        \n",
    "        # Wirte video (optional)\n",
    "        if video:\n",
    "            refine_img = (np.abs(255-temp_img)).astype(np.uint8)\n",
    "            if(left_or_right == \"left\"):\n",
    "                video_refine_left.write(cv2.cvtColor(refine_img, cv2.COLOR_GRAY2RGB))\n",
    "            else:\n",
    "                video_refine_right.write(cv2.cvtColor(refine_img, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_main(cfile,test_name,data_flag,video):\n",
    "            \n",
    "    # Load config file\n",
    "    config = json.load(open(cfile))\n",
    "    data_name = config['data']\n",
    "    # -------------------------------------Save Dir initialization----------------------------------------------------- #\n",
    "    runs_dir = os.path.join(config['val_data']['dir'], test_name, config['trainer']['load_id'])\n",
    "    print(\"runs_dir\",os.path.abspath(runs_dir))\n",
    "    \n",
    "    (out_dir,visual_dir_l, ellipse_dir_l, visual_dir_r, ellipse_dir_r) = (os.path.join(runs_dir,\"InferResults\"),\n",
    "            os.path.join(runs_dir,\"InferResults\",\"visual_left\"),\n",
    "            os.path.join(runs_dir,\"InferResults\",\"ellipse_params_left\"),\n",
    "            os.path.join(runs_dir,\"InferResults\",\"visual_right\"),\n",
    "            os.path.join(runs_dir,\"InferResults\",\"ellipse_params_right\"))\n",
    "        \n",
    "    for t in (out_dir,visual_dir_l,ellipse_dir_l,visual_dir_r,ellipse_dir_r):\n",
    "        if not(os.path.isdir(t)): os.makedirs(t)   \n",
    "            \n",
    "    if video:\n",
    "        global video_entropy_left,video_entropy_partial_left,video_refine_left,video_entropy_right,video_entropy_partial_right,video_refine_right\n",
    "        video_entropy_left = cv2.VideoWriter(os.path.join(out_dir, \"entropy_left.avi\"), cv2.VideoWriter_fourcc(*\"XVID\"), 30, (321,321))\n",
    "        video_entropy_partial_left = cv2.VideoWriter(os.path.join(out_dir, \"entropy_partial_left.avi\"), cv2.VideoWriter_fourcc(*\"XVID\"), 30, (321,321))\n",
    "        video_refine_left = cv2.VideoWriter(os.path.join(out_dir, \"refine_left.avi\"), cv2.VideoWriter_fourcc(*\"XVID\"), 30, (321,321))\n",
    "\n",
    "        video_entropy_right = cv2.VideoWriter(os.path.join(out_dir, \"entropy_right.avi\"), cv2.VideoWriter_fourcc(*\"XVID\"), 30, (321,321))\n",
    "        video_entropy_partial_right = cv2.VideoWriter(os.path.join(out_dir, \"entropy_partial_right.avi\"), cv2.VideoWriter_fourcc(*\"XVID\"), 30, (321,321))\n",
    "        video_refine_right = cv2.VideoWriter(os.path.join(out_dir, \"refine_right.avi\"), cv2.VideoWriter_fourcc(*\"XVID\"), 30, (321,321))\n",
    "    \n",
    "    # -------------------------------------Gpu Device && Tensorboard--------------------------------------------------- #\n",
    "    global device\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    # -------------------------------------Model and Optimizer Initialize-------------------------------------------------- #\n",
    "    arch = config['arch']\n",
    "    model = get_model(\"A\")\n",
    "    model.cuda()\n",
    "    \n",
    "    # Load dict\n",
    "    checkpoint_dir = os.path.join(config['trainer']['runs_dir'], data_name+\"-\"+config['trainer']['load_id'])\n",
    "    print(\"load checkpoingts from {}\".format(os.path.abspath(checkpoint_dir)))\n",
    "    checkpoint = load_checkpoint(os.path.join(checkpoint_dir), False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    vd = config['val_data'] # Prepare test dataset\n",
    "    test_patch = test_name+\"/crop\"\n",
    "    val_set_left = ASGaze_data(datapath=vd['dir'], name=test_patch,split=\"left\",flag=data_flag) \n",
    "    val_loader_left = torch.utils.data.DataLoader(val_set_left, batch_size=vd['batch_size'], shuffle=vd['shuffle'], num_workers=vd['num_workers'])\n",
    "    \n",
    "    val_set_right = ASGaze_data(datapath=vd['dir'], name=test_patch,split=\"right\",flag=data_flag) \n",
    "    val_loader_right = torch.utils.data.DataLoader(val_set_right, batch_size=vd['batch_size'], shuffle=vd['shuffle'], num_workers=vd['num_workers'])\n",
    "\n",
    "    if data_flag == 0:\n",
    "        with torch.no_grad():\n",
    "            inference(val_loader_left, model, \"left\", out_dir, video)\n",
    "            print(\"Left eye inference finish\")\n",
    "            inference(val_loader_right, model, \"right\", out_dir, video)\n",
    "            print(\"Right eye inference finish\")\n",
    "        pass\n",
    "    \n",
    "    if video:\n",
    "        video_entropy_left.release()\n",
    "        video_entropy_partial_left.release()\n",
    "        video_refine_left.release()\n",
    "\n",
    "        video_entropy_right.release()\n",
    "        video_entropy_partial_right.release()\n",
    "        video_refine_right.release()\n",
    "\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
