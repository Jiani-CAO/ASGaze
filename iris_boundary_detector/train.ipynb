{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:\\\\ASGaze\")\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# filter future warning of tensorboard summary\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "\n",
    "import import_ipynb\n",
    "from iris_boundary_detector.data_sources.ASGaze_data import ASGaze_data\n",
    "from iris_boundary_detector.graph.vgg_unet import get_model\n",
    "from iris_boundary_detector.graph.losses import adjust_learning_rate,MissingLoss,DistanceMapLoss,GeneralizedDiceLoss\n",
    "from iris_boundary_detector.utils.metrics import multi_acc,ComputeIoU\n",
    "from iris_boundary_detector.utils.load_model import data_gpu,save_checkpoint,AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader,model,optimizer,epoch,lr,criterion_missing_loss,criterion_distance_map_loss,criterion_dice_loss,alpha):\n",
    "    \n",
    "    losses,batch_time,accuracy,end = AverageMeter(),AverageMeter(),AverageMeter(),time.time()\n",
    "    \n",
    "    model.train()\n",
    "    compute_iou,length = ComputeIoU(3),len(train_loader)\n",
    "    \n",
    "    for i, (data_id, img, gt, one_hot, rotated_rect, rect_trans, iris_missing_weights, distMap) in enumerate(train_loader):\n",
    "        print(i)\n",
    "        optimizer.zero_grad() \n",
    "        out = model(data_gpu(img, device))   \n",
    "        \n",
    "        missing_loss = criterion_missing_loss(out,data_gpu(gt, device))    \n",
    "        iris_missing_loss = missing_loss*(iris_missing_weights).to(torch.float32).to(device)\n",
    "        iris_missing_loss = torch.mean(iris_missing_loss).to(torch.float32).to(device)\n",
    "        \n",
    "        distance_map_loss = criterion_distance_map_loss(out,(distMap).to(device))\n",
    "        \n",
    "        dice_loss = criterion_dice_loss(out,data_gpu(gt, device))\n",
    "        # Overall loss\n",
    "        loss = iris_missing_loss + (1-alpha[epoch])*distance_map_loss + alpha[epoch]*(dice_loss)\n",
    "        \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        acc = multi_acc(f.softmax(out,dim=1),data_gpu(gt, device))\n",
    "        compute_iou(torch.argmax(f.softmax(out, dim=1), dim=1),data_gpu(gt, device))\n",
    "        \n",
    "        losses.update(loss.item())\n",
    "        accuracy.update(acc.item())\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        if i%(length//3) ==0:\n",
    "            print(\"Train epoch {} ({}/{}): [Loss: {} Learning rate: {} batch_time: {}]\".\n",
    "                format(epoch,i, length, losses.avg, lr, batch_time.avg))\n",
    "            \n",
    "    ious = compute_iou.get_ious()\n",
    "    miou = compute_iou.get_miou()\n",
    "    \n",
    "    # Train log\n",
    "    for item in ious:\n",
    "        writer.add_scalar('Train/IoU:{}'.format(item),ious[item],epoch)\n",
    "    writer.add_scalar('Train/LR', lr, epoch)\n",
    "    writer.add_scalar('Train/Loss', losses.avg, epoch)\n",
    "    writer.add_scalar(\"Train/BatchTime\", batch_time.avg, epoch)\n",
    "    writer.add_scalar(\"Train/Pixel Accuracy\", accuracy.avg, epoch)    \n",
    "    writer.add_scalar('Train/mIoU',miou,epoch)\n",
    "    \n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cfile):\n",
    "    \n",
    "    # Load config file\n",
    "    config = json.load(open(cfile))\n",
    "    data_name = config['data']\n",
    "    # -------------------------------------Save Dir initialization----------------------------------------------------- #\n",
    "    runs_dir = os.path.join(config['trainer']['runs_dir'], data_name+\"-\"+datetime.datetime.now().strftime('%m%d-%H%M'))\n",
    "    (save_dir,log_dir) = (os.path.join(runs_dir,'checkpoints'),os.path.join(runs_dir,'log'))\n",
    "    for t in (runs_dir,save_dir,log_dir):\n",
    "        if not(os.path.isdir(t)): os.makedirs(t)\n",
    "            \n",
    "    # -------------------------------------Gpu Device && Tensorboard--------------------------------------------------- #\n",
    "    global device, writer\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    # -------------------------------------Model and Optimizer Initialize-------------------------------------------------- #\n",
    "    model = get_model(\"A\") # Initial model\n",
    "    model.cuda()\n",
    "    # Initial optimizer from config file\n",
    "    op_type, op = config['optimizer']['type'], config['optimizer']['args']\n",
    "    optimizer = getattr(torch.optim,op_type)(model.parameters(), lr=op['lr'], weight_decay=op['weight_decay'])\n",
    "    \n",
    "    criterion_missing_loss = MissingLoss(gamma=2)\n",
    "    criterion_distance_map_loss = DistanceMapLoss()\n",
    "    criterion_dice_loss = GeneralizedDiceLoss(softmax=True, reduction=True)\n",
    "    \n",
    "    # -------------------------------------Model and Data Initialize--------------------------------------------------- #\n",
    "    data_flag = 1\n",
    "    td = config['train_data'] # Prepare train dataset\n",
    "    train_set = ASGaze_data(datapath=td['dir'], name=data_name,split='train',flag=data_flag)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=td['batch_size'], \n",
    "                                    shuffle=td['shuffle'], num_workers=td['num_workers'], drop_last=td['drop_last'])\n",
    "\n",
    "    # Train initialization\n",
    "    t_c, best_loss, start_epoch = config['trainer'], np.inf, 0\n",
    "    print(\"outputs:\",os.path.abspath(t_c['runs_dir']))\n",
    "    \n",
    "    alpha=np.zeros(t_c['epochs'])\n",
    "    alpha[:]=1 - np.arange(1,t_c['epochs']+1)/t_c['epochs']\n",
    "    alpha[alpha<0.5]=0.5\n",
    "        \n",
    "    for epoch in range(start_epoch, t_c['epochs']):\n",
    "        print(\"epoch\",epoch)\n",
    "        \n",
    "        # Learning rate adjustment\n",
    "        lr_c = config['lr_scheduler']['args']\n",
    "        lr = adjust_learning_rate(optimizer, op['lr'], lr_c['gamma'], lr_c['step_size'], epoch)\n",
    "        \n",
    "        diff = 0.2 # Learning difficulty setting\n",
    "        train_set.set_difficulty(diff)\n",
    "        train_loss = train_epoch(train_loader,model,optimizer,epoch,lr,criterion_missing_loss,criterion_distance_map_loss,criterion_dice_loss,alpha) # epoch train iteration\n",
    "            \n",
    "        # Save newest model\n",
    "        save_checkpoint({'epoch': epoch, 'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict(),'loss':best_loss},save_dir,flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    seg_train_config = \"./configs/segmentation_train.json\"\n",
    "    main(seg_train_config)\n",
    "    print('DONE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
